{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14e804d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate post_ids: 0\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   post_id       500 non-null    object        \n",
      " 1   title         500 non-null    object        \n",
      " 2   author        496 non-null    object        \n",
      " 3   score         500 non-null    int64         \n",
      " 4   created_utc   500 non-null    datetime64[ns]\n",
      " 5   num_comments  500 non-null    int64         \n",
      " 6   selftext      500 non-null    object        \n",
      " 7   url           500 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(5)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "post_id         0\n",
      "title           0\n",
      "author          4\n",
      "score           0\n",
      "created_utc     0\n",
      "num_comments    0\n",
      "selftext        0\n",
      "url             0\n",
      "dtype: int64\n",
      "\n",
      "Row Count: 500\n",
      "\n",
      "Fixed CSV saved to 'reddit_posts_fixed.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "# Step 8.1: Read the CSV with robust parsing\n",
    "try:\n",
    "    data = pd.read_csv('reddit_posts.csv', quoting=csv.QUOTE_ALL, escapechar='\\\\', encoding='utf-8', on_bad_lines='warn')\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV: {e}\")\n",
    "    # Fallback: Manual parsing\n",
    "    with open('reddit_posts.csv', 'r', encoding='utf-8') as file:\n",
    "        raw_data = file.read()\n",
    "    csv_buffer = StringIO(raw_data)\n",
    "    data = pd.read_csv(csv_buffer, quoting=csv.QUOTE_ALL, escapechar='\\\\', encoding='utf-8', on_bad_lines='warn')\n",
    "\n",
    "# Step 8.2: Text Preprocessing for title and selftext\n",
    "def clean_text(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Encode to handle emojis and non-ASCII characters\n",
    "    text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "    # Replace newlines and carriage returns with spaces\n",
    "    text = re.sub(r'[\\n\\r]+', ' ', text)\n",
    "    # Escape double quotes for CSV compatibility\n",
    "    text = text.replace('\"', '\"\"')\n",
    "    # Normalize multiple spaces and tabs\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Simplify URLs and user mentions\n",
    "    text = re.sub(r'https?://\\S+', '[URL]', text)\n",
    "    text = re.sub(r'u/\\S+', '[USER]', text)\n",
    "    # Trim leading/trailing spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to title and selftext\n",
    "data['title'] = data['title'].apply(clean_text)\n",
    "data['selftext'] = data['selftext'].apply(clean_text)\n",
    "\n",
    "# Step 8.3: Validate and clean other columns\n",
    "# Convert created_utc to datetime\n",
    "data['created_utc'] = pd.to_datetime(data['created_utc'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing post_id\n",
    "data = data.dropna(subset=['post_id'])\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"Duplicate post_ids:\", data['post_id'].duplicated().sum())\n",
    "\n",
    "# Step 8.4: Basic validation\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\nRow Count:\", len(data))\n",
    "\n",
    "# Step 8.5: Save the corrected CSV\n",
    "data.to_csv('reddit_posts_fixed.csv', index=False, quoting=csv.QUOTE_ALL, escapechar='\\\\', encoding='utf-8')\n",
    "print(\"\\nFixed CSV saved to 'reddit_posts_fixed.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
